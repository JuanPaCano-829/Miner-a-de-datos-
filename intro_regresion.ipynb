{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Lineal con Penalización L1 y L2\n",
    "\n",
    "En este notebook exploraremos las diferencias entre la regresión lineal con penalización L1 (Lasso) y L2 (Ridge).\n",
    "\n",
    "## Objetivos de aprendizaje:\n",
    "- Entender cómo L2 (Ridge) maneja variables correlacionadas\n",
    "- Ver cómo L1 (Lasso) realiza selección de variables\n",
    "- Comparar los coeficientes resultantes de cada método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Configuración para reproducibilidad\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generación de Datos Sintéticos\n",
    "\n",
    "Crearemos un dataset con las siguientes características:\n",
    "- **Variables correlacionadas**: X1, X2, X3 estarán altamente correlacionadas\n",
    "- **Variables importantes**: X4, X5 tendrán efecto real en Y\n",
    "- **Variables irrelevantes**: X6, X7, X8, X9, X10 no tendrán efecto en Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_illustrative_data(n_samples=60, n_features=50, noise=2.0):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 1. Variables con alta multicolinealidad (X1, X2, X3)\n",
    "    # Comparten el 99% de su varianza\n",
    "    shared_signal = np.random.randn(n_samples, 1)\n",
    "    X_corr = shared_signal + np.random.randn(n_samples, 3) * 0.01\n",
    "    \n",
    "    # 2. Variables independientes e importantes\n",
    "    X_important = np.random.randn(n_samples, 2)\n",
    "    \n",
    "    # 3. Variables de ruido puro (muchas más que las importantes)\n",
    "    X_noise = np.random.randn(n_samples, n_features - 5)\n",
    "    \n",
    "    X = np.hstack([X_corr, X_important, X_noise])\n",
    "    \n",
    "    # 4. Generar Y (solo las primeras 5 variables tienen impacto)\n",
    "    # Coeficientes: [10, 10, 10, 5, -5, 0, 0, 0, ...]\n",
    "    true_beta = np.zeros(n_features)\n",
    "    true_beta[0:3] = 10.0  # Las correlacionadas\n",
    "    true_beta[3:5] = [5.0, -5.0] # Las independientes\n",
    "    \n",
    "    y = X @ true_beta + np.random.randn(n_samples) * noise\n",
    "    \n",
    "    return X, y, true_beta\n",
    "n_features = 9\n",
    "X, y, true_coefficients = generate_illustrative_data(n_samples=10, n_features=n_features, noise = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploración de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns=[f\"X{i}\" for i in  range(n_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = X.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, vmin=-1, vmax=1, square=True)\n",
    "plt.title('Matriz de Correlación de Variables Explicativas', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlaciones entre X1, X2, X3:\")\n",
    "print(correlation_matrix.loc[['X1', 'X2', 'X3'], ['X1', 'X2', 'X3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. División y Normalización\n",
    "\n",
    "Es importante normalizar los datos cuando usamos regularización para que todas las variables estén en la misma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Normalización (importante para regularización)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train_scaled.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparación de Modelos\n",
    "\n",
    "Entrenaremos tres modelos:\n",
    "1. **Regresión Lineal Ordinaria** (sin regularización)\n",
    "2. **Ridge** (penalización L2)\n",
    "3. **Lasso** (penalización L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores de alpha para experimentar\n",
    "alpha = 1.0\n",
    "\n",
    "# Entrenar modelos\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=alpha)\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Scores\n",
    "print(\"R² Score en conjunto de entrenamiento:\")\n",
    "print(f\"  Regresión Lineal: {lr.score(X_train_scaled, y_train):.4f}\")\n",
    "print(f\"  Ridge (L2):       {ridge.score(X_train_scaled, y_train):.4f}\")\n",
    "print(f\"  Lasso (L1):       {lasso.score(X_train_scaled, y_train):.4f}\")\n",
    "\n",
    "print(\"\\nR² Score en conjunto de prueba:\")\n",
    "print(f\"  Regresión Lineal: {lr.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"  Ridge (L2):       {ridge.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"  Lasso (L1):       {lasso.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis de Coeficientes\n",
    "\n",
    "Aquí veremos las diferencias clave:\n",
    "- **L2 (Ridge)** distribuye el peso entre variables correlacionadas\n",
    "- **L1 (Lasso)** hace selección de variables, llevando algunos coeficientes a exactamente 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con los coeficientes\n",
    "coef_df = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Verdadero': list(true_coefficients),\n",
    "    'Reg. Lineal': lr.coef_,\n",
    "    'Ridge (L2)': ridge.coef_,\n",
    "    'Lasso (L1)': lasso.coef_\n",
    "})\n",
    "\n",
    "print(\"Comparación de Coeficientes:\")\n",
    "print(coef_df.to_string(index=False))\n",
    "\n",
    "# Contar variables con coeficiente cero en Lasso\n",
    "n_zero_lasso = np.sum(np.abs(lasso.coef_) < 1e-10)\n",
    "print(f\"\\nVariables eliminadas por Lasso (coef ≈ 0): {n_zero_lasso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualización de Coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras comparando coeficientes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "models = ['Reg. Lineal', 'Ridge (L2)', 'Lasso (L1)']\n",
    "colors = ['steelblue', 'forestgreen', 'crimson']\n",
    "\n",
    "for idx, (model, color) in enumerate(zip(models, colors)):\n",
    "    ax = axes[idx]\n",
    "    x_pos = np.arange(len(X.columns))\n",
    "    \n",
    "    # Coeficientes del modelo\n",
    "    coefs = coef_df[model].values\n",
    "    \n",
    "    # Coeficientes verdaderos como líneas\n",
    "    true_coefs = coef_df['Verdadero'].values\n",
    "    \n",
    "    ax.bar(x_pos, coefs, alpha=0.7, color=color, label='Estimado')\n",
    "    ax.scatter(x_pos, true_coefs, color='black', s=100, \n",
    "               marker='_', linewidths=3, label='Verdadero', zorder=5)\n",
    "    \n",
    "    ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)\n",
    "    ax.set_xlabel('Variable', fontsize=11)\n",
    "    ax.set_ylabel('Coeficiente', fontsize=11)\n",
    "    ax.set_title(f'{model}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(X.columns, rotation=45)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Observaciones Clave\n",
    "\n",
    "### Variables Correlacionadas (X1, X2, X3):\n",
    "- **Regresión Lineal**: Los coeficientes pueden ser inestables debido a la multicolinealidad\n",
    "- **Ridge (L2)**: Distribuye el peso entre las variables correlacionadas, reduciendo todos los coeficientes pero manteniéndolos no-cero\n",
    "- **Lasso (L1)**: Tiende a seleccionar una de las variables correlacionadas y eliminar las demás\n",
    "\n",
    "### Variables Sin Efecto (X6-X10):\n",
    "- **Regresión Lineal**: Puede asignar coeficientes no-cero por ruido\n",
    "- **Ridge (L2)**: Reduce los coeficientes pero rara vez los lleva exactamente a cero\n",
    "- **Lasso (L1)**: Tiende a llevar estos coeficientes exactamente a cero (selección de variables)\n",
    "\n",
    "### ¿Cuándo usar cada uno?\n",
    "- **Ridge**: Cuando todas las variables son potencialmente relevantes y hay multicolinealidad\n",
    "- **Lasso**: Cuando queremos selección de variables automática y un modelo más interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experimento: Variando Alpha\n",
    "\n",
    "Veamos cómo cambian los coeficientes con diferentes valores de alpha (intensidad de la penalización)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rango de alphas\n",
    "alphas = np.logspace(-3, 2, 50)\n",
    "\n",
    "ridge_coefs = []\n",
    "lasso_coefs = []\n",
    "ridge_mse_train = []\n",
    "ridge_mse_test = []\n",
    "lasso_mse_train = []\n",
    "lasso_mse_test = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "    lasso_model = Lasso(alpha=alpha, max_iter=10000)\n",
    "    \n",
    "    ridge_model.fit(X_train_scaled, y_train)\n",
    "    lasso_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    ridge_coefs.append(ridge_model.coef_)\n",
    "    lasso_coefs.append(lasso_model.coef_)\n",
    "    \n",
    "    # Calcular MSE para Ridge\n",
    "    y_pred_ridge_train = ridge_model.predict(X_train_scaled)\n",
    "    y_pred_ridge_test = ridge_model.predict(X_test_scaled)\n",
    "    ridge_mse_train.append(mean_squared_error(y_train, y_pred_ridge_train))\n",
    "    ridge_mse_test.append(mean_squared_error(y_test, y_pred_ridge_test))\n",
    "    \n",
    "    # Calcular MSE para Lasso\n",
    "    y_pred_lasso_train = lasso_model.predict(X_train_scaled)\n",
    "    y_pred_lasso_test = lasso_model.predict(X_test_scaled)\n",
    "    lasso_mse_train.append(mean_squared_error(y_train, y_pred_lasso_train))\n",
    "    lasso_mse_test.append(mean_squared_error(y_test, y_pred_lasso_test))\n",
    "\n",
    "ridge_coefs = np.array(ridge_coefs)\n",
    "lasso_coefs = np.array(lasso_coefs)\n",
    "\n",
    "# Visualizar paths de coeficientes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Ridge\n",
    "for i, col in enumerate(X.columns):\n",
    "    axes[0].plot(alphas, ridge_coefs[:, i], label=col, linewidth=2)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('Alpha (λ)', fontsize=12)\n",
    "axes[0].set_ylabel('Coeficiente', fontsize=12)\n",
    "axes[0].set_title('Ridge (L2): Path de Regularización', fontsize=13, fontweight='bold')\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', linewidth=0.8)\n",
    "axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Lasso\n",
    "for i, col in enumerate(X.columns):\n",
    "    axes[1].plot(alphas, lasso_coefs[:, i], label=col, linewidth=2)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_xlabel('Alpha (λ)', fontsize=12)\n",
    "axes[1].set_ylabel('Coeficiente', fontsize=12)\n",
    "axes[1].set_title('Lasso (L1): Path de Regularización', fontsize=13, fontweight='bold')\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', linewidth=0.8)\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observa cómo:\")\n",
    "print(\"- Ridge: Los coeficientes se reducen gradualmente pero nunca llegan exactamente a cero\")\n",
    "print(\"- Lasso: Los coeficientes llegan a cero en diferentes valores de alpha (selección de variables)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Error Cuadrático Medio (MSE) vs Alpha\n",
    "\n",
    "Analicemos cómo cambia el MSE en los conjuntos de entrenamiento y prueba para diferentes valores de alpha. Esto nos ayudará a identificar:\n",
    "- **Underfitting**: Cuando alpha es muy grande, ambos errores son altos\n",
    "- **Overfitting**: Cuando el error de entrenamiento es bajo pero el de prueba es alto\n",
    "- **Punto óptimo**: Donde el error de prueba es mínimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar MSE vs Alpha\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Ridge MSE\n",
    "axes[0].plot(alphas, ridge_mse_train, label='Entrenamiento', linewidth=2.5, \n",
    "             color='forestgreen', marker='o', markersize=3)\n",
    "axes[0].plot(alphas, ridge_mse_test, label='Prueba', linewidth=2.5, \n",
    "             color='crimson', marker='s', markersize=3)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('Alpha (λ)', fontsize=12)\n",
    "axes[0].set_ylabel('MSE (Error Cuadrático Medio)', fontsize=12)\n",
    "axes[0].set_title('Ridge (L2): MSE vs Alpha', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Encontrar el alpha óptimo para Ridge\n",
    "optimal_alpha_ridge = alphas[np.argmin(ridge_mse_test)]\n",
    "min_mse_ridge = np.min(ridge_mse_test)\n",
    "axes[0].axvline(x=optimal_alpha_ridge, color='blue', linestyle='--', \n",
    "                linewidth=2, alpha=0.7, label=f'Óptimo α={optimal_alpha_ridge:.4f}')\n",
    "axes[0].legend(fontsize=11)\n",
    "\n",
    "# Lasso MSE\n",
    "axes[1].plot(alphas, lasso_mse_train, label='Entrenamiento', linewidth=2.5, \n",
    "             color='forestgreen', marker='o', markersize=3)\n",
    "axes[1].plot(alphas, lasso_mse_test, label='Prueba', linewidth=2.5, \n",
    "             color='crimson', marker='s', markersize=3)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_xlabel('Alpha (λ)', fontsize=12)\n",
    "axes[1].set_ylabel('MSE (Error Cuadrático Medio)', fontsize=12)\n",
    "axes[1].set_title('Lasso (L1): MSE vs Alpha', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Encontrar el alpha óptimo para Lasso\n",
    "optimal_alpha_lasso = alphas[np.argmin(lasso_mse_test)]\n",
    "min_mse_lasso = np.min(lasso_mse_test)\n",
    "axes[1].axvline(x=optimal_alpha_lasso, color='blue', linestyle='--', \n",
    "                linewidth=2, alpha=0.7, label=f'Óptimo α={optimal_alpha_lasso:.4f}')\n",
    "axes[1].legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RESULTADOS DE OPTIMIZACIÓN\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nRidge (L2):\")\n",
    "print(f\"  Alpha óptimo: {optimal_alpha_ridge:.6f}\")\n",
    "print(f\"  MSE mínimo (prueba): {min_mse_ridge:.6f}\")\n",
    "print(f\"  MSE entrenamiento: {ridge_mse_train[np.argmin(ridge_mse_test)]:.6f}\")\n",
    "\n",
    "print(f\"\\nLasso (L1):\")\n",
    "print(f\"  Alpha óptimo: {optimal_alpha_lasso:.6f}\")\n",
    "print(f\"  MSE mínimo (prueba): {min_mse_lasso:.6f}\")\n",
    "print(f\"  MSE entrenamiento: {lasso_mse_train[np.argmin(lasso_mse_test)]:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INTERPRETACIÓN\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nObserva que:\")\n",
    "print(\"- Cuando alpha es muy pequeño → El modelo se ajusta mucho a los datos de entrenamiento\")\n",
    "print(\"  (MSE de entrenamiento bajo, pero puede haber sobreajuste)\")\n",
    "print(\"\\n- Cuando alpha es muy grande → El modelo está muy regularizado\")\n",
    "print(\"  (MSE alto en ambos conjuntos, indica subajuste)\")\n",
    "print(\"\\n- El alpha óptimo balancea el sesgo y la varianza del modelo\")\n",
    "print(\"  (MSE de prueba mínimo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Validación Cruzada: El Método Correcto\n",
    "\n",
    "El método anterior tiene un problema: **usamos el conjunto de prueba para seleccionar alpha**, lo cual puede introducir sesgo. El método correcto es usar **validación cruzada (cross-validation)** en el conjunto de entrenamiento.\n",
    "\n",
    "### ¿Por qué validación cruzada?\n",
    "\n",
    "1. **No contamina el conjunto de prueba**: El conjunto de prueba solo se usa una vez al final para evaluar el modelo final\n",
    "2. **Más robusto**: Usa múltiples particiones de los datos para estimar el rendimiento\n",
    "3. **Mejor generalización**: Reduce la varianza en la selección del hiperparámetro\n",
    "\n",
    "### Métodos disponibles:\n",
    "\n",
    "- **RidgeCV**: Ridge con validación cruzada integrada\n",
    "- **LassoCV**: Lasso con validación cruzada integrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelos con validación cruzada\n",
    "# cv=5 significa 5-fold cross-validation\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5, max_iter=10000, random_state=42)\n",
    "\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RESULTADOS CON VALIDACIÓN CRUZADA (5-FOLD)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nRidge (L2):\")\n",
    "print(f\"  Alpha óptimo (CV): {ridge_cv.alpha_:.6f}\")\n",
    "ridge_pred_test = ridge_cv.predict(X_test_scaled)\n",
    "ridge_mse_cv = mean_squared_error(y_test, ridge_pred_test)\n",
    "print(f\"  MSE en prueba: {ridge_mse_cv:.6f}\")\n",
    "print(f\"  R² en prueba: {ridge_cv.score(X_test_scaled, y_test):.6f}\")\n",
    "\n",
    "print(f\"\\nLasso (L1):\")\n",
    "print(f\"  Alpha óptimo (CV): {lasso_cv.alpha_:.6f}\")\n",
    "lasso_pred_test = lasso_cv.predict(X_test_scaled)\n",
    "lasso_mse_cv = mean_squared_error(y_test, lasso_pred_test)\n",
    "print(f\"  MSE en prueba: {lasso_mse_cv:.6f}\")\n",
    "print(f\"  R² en prueba: {lasso_cv.score(X_test_scaled, y_test):.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARACIÓN: Método anterior vs Validación Cruzada\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nRidge:\")\n",
    "print(f\"  Alpha (método anterior): {optimal_alpha_ridge:.6f}\")\n",
    "print(f\"  Alpha (validación cruzada): {ridge_cv.alpha_:.6f}\")\n",
    "print(f\"  Diferencia: {abs(optimal_alpha_ridge - ridge_cv.alpha_):.6f}\")\n",
    "\n",
    "print(f\"\\nLasso:\")\n",
    "print(f\"  Alpha (método anterior): {optimal_alpha_lasso:.6f}\")\n",
    "print(f\"  Alpha (validación cruzada): {lasso_cv.alpha_:.6f}\")\n",
    "print(f\"  Diferencia: {abs(optimal_alpha_lasso - lasso_cv.alpha_):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de Coeficientes con Validación Cruzada\n",
    "\n",
    "Veamos cómo cambian los coeficientes al usar el alpha seleccionado por validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con coeficientes obtenidos por validación cruzada\n",
    "coef_cv_df = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Verdadero': list(true_coefficients),\n",
    "    'Ridge (CV)': ridge_cv.coef_,\n",
    "    'Lasso (CV)': lasso_cv.coef_\n",
    "})\n",
    "\n",
    "print(\"Coeficientes con Validación Cruzada:\")\n",
    "print(coef_cv_df.to_string(index=False))\n",
    "\n",
    "# Contar variables eliminadas por Lasso CV\n",
    "n_zero_lasso_cv = np.sum(np.abs(lasso_cv.coef_) < 1e-10)\n",
    "print(f\"\\nVariables eliminadas por Lasso CV (coef ≈ 0): {n_zero_lasso_cv}\")\n",
    "\n",
    "# Visualización\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "models_cv = ['Ridge (CV)', 'Lasso (CV)']\n",
    "colors_cv = ['forestgreen', 'crimson']\n",
    "\n",
    "for idx, (model, color) in enumerate(zip(models_cv, colors_cv)):\n",
    "    ax = axes[idx]\n",
    "    x_pos = np.arange(len(X.columns))\n",
    "    \n",
    "    coefs = coef_cv_df[model].values\n",
    "    true_coefs = coef_cv_df['Verdadero'].values\n",
    "    \n",
    "    ax.bar(x_pos, coefs, alpha=0.7, color=color, label='Estimado (CV)')\n",
    "    ax.scatter(x_pos, true_coefs, color='black', s=100, \n",
    "               marker='_', linewidths=3, label='Verdadero', zorder=5)\n",
    "    \n",
    "    ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)\n",
    "    ax.set_xlabel('Variable', fontsize=11)\n",
    "    ax.set_ylabel('Coeficiente', fontsize=11)\n",
    "    ax.set_title(f'{model}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(X.columns, rotation=45)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de Validación Cruzada\n",
    "\n",
    "LassoCV almacena los errores de validación cruzada para cada valor de alpha probado, lo que nos permite visualizar el proceso de selección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV guarda el MSE promedio de validación cruzada para cada alpha\n",
    "# mse_path_ tiene forma (n_alphas, n_folds) para cada alpha y fold\n",
    "\n",
    "# Calcular MSE promedio y desviación estándar a través de los folds\n",
    "lasso_cv_mean = np.mean(lasso_cv.mse_path_, axis=1)\n",
    "lasso_cv_std = np.std(lasso_cv.mse_path_, axis=1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graficar MSE promedio de CV\n",
    "plt.plot(lasso_cv.alphas_, lasso_cv_mean, 'b-', linewidth=2.5, label='MSE promedio (5-fold CV)')\n",
    "\n",
    "# Agregar banda de error (±1 std)\n",
    "plt.fill_between(lasso_cv.alphas_, \n",
    "                 lasso_cv_mean - lasso_cv_std,\n",
    "                 lasso_cv_mean + lasso_cv_std,\n",
    "                 alpha=0.2, color='blue', label='±1 desviación estándar')\n",
    "\n",
    "# Marcar el alpha óptimo\n",
    "plt.axvline(x=lasso_cv.alpha_, color='red', linestyle='--', \n",
    "            linewidth=2, label=f'Alpha óptimo = {lasso_cv.alpha_:.6f}')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (λ)', fontsize=12)\n",
    "plt.ylabel('MSE', fontsize=12)\n",
    "plt.title('Lasso: Curva de Validación Cruzada (5-Fold)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretación:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"- La línea azul muestra el MSE promedio de validación cruzada\")\n",
    "print(\"- El área sombreada representa la variabilidad entre los folds\")\n",
    "print(\"- La línea vertical roja indica el alpha que minimiza el MSE de CV\")\n",
    "print(\"- Este es el método correcto y más robusto para seleccionar alpha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Este ejercicio demuestra las diferencias fundamentales entre L1 y L2, y las mejores prácticas para su aplicación:\n",
    "\n",
    "### 1. **L2 (Ridge)** es ideal cuando:\n",
    "- Hay multicolinealidad entre variables\n",
    "- Todas las variables son potencialmente importantes\n",
    "- Queremos estabilizar los coeficientes sin eliminar variables\n",
    "- Ridge reduce gradualmente todos los coeficientes pero rara vez los lleva exactamente a cero\n",
    "\n",
    "### 2. **L1 (Lasso)** es ideal cuando:\n",
    "- Queremos selección automática de variables\n",
    "- Buscamos un modelo interpretable y parsimonioso\n",
    "- Sospechamos que muchas variables son irrelevantes\n",
    "- Lasso lleva coeficientes exactamente a cero, eliminando variables del modelo\n",
    "\n",
    "### 3. **Selección del Hiperparámetro Alpha**:\n",
    "- **NUNCA usar el conjunto de prueba para seleccionar hiperparámetros** (contamina la evaluación final)\n",
    "- **Validación cruzada es el método correcto**: usa solo el conjunto de entrenamiento\n",
    "- Herramientas recomendadas: `RidgeCV` y `LassoCV` de scikit-learn\n",
    "- Un alpha muy pequeño puede llevar a sobreajuste (overfitting)\n",
    "- Un alpha muy grande puede llevar a subajuste (underfitting)\n",
    "- El alpha óptimo balancea sesgo y varianza\n",
    "\n",
    "### 4. **Flujo de trabajo recomendado**:\n",
    "1. Dividir datos en entrenamiento y prueba (80/20 o 70/30)\n",
    "2. Usar validación cruzada en el conjunto de entrenamiento para seleccionar alpha\n",
    "3. Entrenar el modelo final con el alpha óptimo en todo el conjunto de entrenamiento\n",
    "4. Evaluar SOLO UNA VEZ en el conjunto de prueba\n",
    "\n",
    "### 5. **Aplicaciones Prácticas**:\n",
    "- **Ridge**: Predicción de precios con múltiples características correlacionadas (área, habitaciones, ubicación)\n",
    "- **Lasso**: Análisis genómico donde solo algunos genes son relevantes entre miles\n",
    "- **Elastic Net**: Combina L1 y L2 para obtener lo mejor de ambos mundos\n",
    "\n",
    "### 6. **Recursos adicionales**:\n",
    "- Documentación de scikit-learn sobre regularización lineal\n",
    "- \"The Elements of Statistical Learning\" - Hastie, Tibshirani, Friedman (Capítulo 3)\n",
    "- Cross-validation en machine learning: [scikit-learn User Guide](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mineria-datos-itam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
